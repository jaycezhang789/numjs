pub mod buffer;
pub mod dtype;
pub mod element;
mod macros;
pub mod metrics;

use buffer::MatrixBuffer;
use dtype::{promote_many, promote_pair, DType};
use element::Element as ElementTrait;
use num_traits::{Bounded, Float, FromPrimitive, PrimInt, Signed, ToPrimitive, Unsigned};

use ndarray::Array2;
use std::convert::TryInto;

#[cfg(feature = "npy")]
use py_literal::Value as PyValue;

#[cfg(feature = "npy")]
use std::io::{Cursor, Read, Write};

#[cfg(feature = "npy")]
use zip::{write::FileOptions, CompressionMethod, ZipArchive, ZipWriter};

#[cfg(feature = "linalg")]
use nalgebra::{DMatrix, SymmetricEigen};

pub use metrics::{copy_bytes_total, reset_copy_bytes, take_copy_bytes};
pub type CoreResult<T> = Result<T, String>;

// ---------------------------------------------------------------------
// Numerically stable reductions (pairwise sum/dot, Welford mean/variance)
// ---------------------------------------------------------------------
fn reduction_accumulator_dtype(dtype: DType) -> DType {
    match dtype {
        DType::Bool => DType::Int64,
        DType::Int8 | DType::Int16 | DType::Int32 | DType::Int64 => DType::Int64,
        DType::UInt8 | DType::UInt16 | DType::UInt32 | DType::UInt64 => DType::UInt64,
        DType::Float32 => DType::Float32,
        DType::Float64 => DType::Float64,
        DType::Fixed64 => DType::Fixed64,
    }
}

fn apply_reduce_output_dtype(
    result: MatrixBuffer,
    target: Option<DType>,
) -> CoreResult<MatrixBuffer> {
    if let Some(target_dtype) = target {
        if target_dtype == result.dtype() {
            Ok(result)
        } else {
            result.cast(target_dtype)
        }
    } else {
        Ok(result)
    }
}

fn sum_bool(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    let contiguous = matrix.to_contiguous()?;
    let slice = contiguous.try_as_slice::<bool>()?;
    let mut total: i128 = 0;
    for &value in slice {
        if value {
            total += 1;
        }
    }
    if total > i64::MAX as i128 {
        return Err("sum(bool): overflow while counting true values".into());
    }
    MatrixBuffer::from_vec(vec![total as i64], 1, 1).map_err(Into::into)
}

fn sum_signed_numeric<T>(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + ToPrimitive + ElementTrait,
{
    let contiguous = matrix.to_contiguous()?;
    let slice = contiguous.try_as_slice::<T>()?;
    let mut total: i128 = 0;
    for &value in slice {
        let v = value
            .to_i64()
            .ok_or_else(|| "sum: failed to convert signed value to i64".to_string())?;
        total = total
            .checked_add(v as i128)
            .ok_or_else(|| "sum: signed accumulator overflow".to_string())?;
    }
    if total < i64::MIN as i128 || total > i64::MAX as i128 {
        return Err("sum: signed result exceeds int64 range".into());
    }
    MatrixBuffer::from_vec(vec![total as i64], 1, 1).map_err(Into::into)
}

fn sum_unsigned_numeric<T>(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Unsigned + ToPrimitive + ElementTrait,
{
    let contiguous = matrix.to_contiguous()?;
    let slice = contiguous.try_as_slice::<T>()?;
    let mut total: u128 = 0;
    for &value in slice {
        let v = value
            .to_u64()
            .ok_or_else(|| "sum: failed to convert unsigned value to u64".to_string())?;
        total = total
            .checked_add(v as u128)
            .ok_or_else(|| "sum: unsigned accumulator overflow".to_string())?;
    }
    if total > u64::MAX as u128 {
        return Err("sum: unsigned result exceeds uint64 range".into());
    }
    MatrixBuffer::from_vec(vec![total as u64], 1, 1).map_err(Into::into)
}

fn sum_float_numeric<T>(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let contiguous = matrix.to_contiguous()?;
    let slice = contiguous.try_as_slice::<T>()?;
    let mut sum = T::zero();
    let mut compensation = T::zero();
    for &value in slice {
        let y = value - compensation;
        let t = sum + y;
        compensation = (t - sum) - y;
        sum = t;
    }
    MatrixBuffer::from_vec(vec![sum], 1, 1).map_err(Into::into)
}

fn sum_fixed64(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    let scale = ensure_fixed64(matrix)?;
    let data = matrix_to_fixed_vec(matrix)?;
    let mut total: i128 = 0;
    for value in data {
        total = total
            .checked_add(value as i128)
            .ok_or_else(|| "sum(Fixed64): overflow".to_string())?;
    }
    if total < i64::MIN as i128 || total > i64::MAX as i128 {
        return Err("sum(Fixed64): overflow".into());
    }
    MatrixBuffer::from_fixed_i64_vec(vec![total as i64], 1, 1, scale)
}

pub fn sum(matrix: &MatrixBuffer, target_dtype: Option<DType>) -> CoreResult<MatrixBuffer> {
    let result = match matrix.dtype() {
        DType::Bool => sum_bool(matrix),
        DType::Int8 => sum_signed_numeric::<i8>(matrix),
        DType::Int16 => sum_signed_numeric::<i16>(matrix),
        DType::Int32 => sum_signed_numeric::<i32>(matrix),
        DType::Int64 => sum_signed_numeric::<i64>(matrix),
        DType::UInt8 => sum_unsigned_numeric::<u8>(matrix),
        DType::UInt16 => sum_unsigned_numeric::<u16>(matrix),
        DType::UInt32 => sum_unsigned_numeric::<u32>(matrix),
        DType::UInt64 => sum_unsigned_numeric::<u64>(matrix),
        DType::Float32 => sum_float_numeric::<f32>(matrix),
        DType::Float64 => sum_float_numeric::<f64>(matrix),
        DType::Fixed64 => sum_fixed64(matrix),
    }?;
    apply_reduce_output_dtype(result, target_dtype)
}

fn dot_bool(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    let lhs = a.try_as_slice::<bool>()?;
    let rhs = b.try_as_slice::<bool>()?;
    let mut total: i128 = 0;
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        if x && y {
            total = total
                .checked_add(1)
                .ok_or_else(|| "dot(bool, bool): overflow".to_string())?;
        }
    }
    MatrixBuffer::from_vec(vec![total as i64], 1, 1).map_err(Into::into)
}

fn dot_signed_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + ToPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut total: i128 = 0;
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let xi = x
            .to_i64()
            .ok_or_else(|| "dot: failed to convert signed multiplicand".to_string())?;
        let yi = y
            .to_i64()
            .ok_or_else(|| "dot: failed to convert signed multiplicand".to_string())?;
        total = total
            .checked_add((xi as i128) * (yi as i128))
            .ok_or_else(|| "dot: signed accumulator overflow".to_string())?;
    }
    if total < i64::MIN as i128 || total > i64::MAX as i128 {
        return Err("dot: signed result exceeds int64 range".into());
    }
    MatrixBuffer::from_vec(vec![total as i64], 1, 1).map_err(Into::into)
}

fn dot_unsigned_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Unsigned + ToPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut total: u128 = 0;
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let xi = x
            .to_u64()
            .ok_or_else(|| "dot: failed to convert unsigned multiplicand".to_string())?;
        let yi = y
            .to_u64()
            .ok_or_else(|| "dot: failed to convert unsigned multiplicand".to_string())?;
        total = total
            .checked_add((xi as u128) * (yi as u128))
            .ok_or_else(|| "dot: unsigned accumulator overflow".to_string())?;
    }
    if total > u64::MAX as u128 {
        return Err("dot: unsigned result exceeds uint64 range".into());
    }
    MatrixBuffer::from_vec(vec![total as u64], 1, 1).map_err(Into::into)
}

fn dot_float_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut sum = T::zero();
    let mut compensation = T::zero();
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let product = x * y;
        let y_comp = product - compensation;
        let t = sum + y_comp;
        compensation = (t - sum) - y_comp;
        sum = t;
    }
    MatrixBuffer::from_vec(vec![sum], 1, 1).map_err(Into::into)
}

pub fn dot(
    a: &MatrixBuffer,
    b: &MatrixBuffer,
    target_dtype: Option<DType>,
) -> CoreResult<MatrixBuffer> {
    if a.rows() != b.rows() || a.cols() != b.cols() {
        return Err("dot: shape mismatch".into());
    }
    if a.dtype() == DType::Fixed64 || b.dtype() == DType::Fixed64 {
        return Err(
            "dot(Fixed64): convert operands to float64 via astype(\"float64\") before reducing"
                .into(),
        );
    }
    let mul_dtype = promote_pair(a.dtype(), b.dtype()).map_err(|err| format!("dot: {err}"))?;
    let acc_dtype = reduction_accumulator_dtype(mul_dtype);

    let left_cast = if a.dtype() == mul_dtype {
        a.to_contiguous()?
    } else {
        a.cast(mul_dtype)?.to_contiguous()?
    };
    let right_cast = if b.dtype() == mul_dtype {
        b.to_contiguous()?
    } else {
        b.cast(mul_dtype)?.to_contiguous()?
    };

    let result = match mul_dtype {
        DType::Bool => dot_bool(&left_cast, &right_cast),
        DType::Int8 => dot_signed_numeric::<i8>(&left_cast, &right_cast),
        DType::Int16 => dot_signed_numeric::<i16>(&left_cast, &right_cast),
        DType::Int32 => dot_signed_numeric::<i32>(&left_cast, &right_cast),
        DType::Int64 => dot_signed_numeric::<i64>(&left_cast, &right_cast),
        DType::UInt8 => dot_unsigned_numeric::<u8>(&left_cast, &right_cast),
        DType::UInt16 => dot_unsigned_numeric::<u16>(&left_cast, &right_cast),
        DType::UInt32 => dot_unsigned_numeric::<u32>(&left_cast, &right_cast),
        DType::UInt64 => dot_unsigned_numeric::<u64>(&left_cast, &right_cast),
        DType::Float32 => dot_float_numeric::<f32>(&left_cast, &right_cast),
        DType::Float64 => dot_float_numeric::<f64>(&left_cast, &right_cast),
        DType::Fixed64 => unreachable!(),
    }?;

    let normalized = if acc_dtype == result.dtype() {
        result
    } else {
        result.cast(acc_dtype)?
    };

    apply_reduce_output_dtype(normalized, target_dtype)
}

pub fn welford_mean_variance(buffer: &MatrixBuffer, sample: bool) -> (f64, f64) {
    let mut n: f64 = 0.0;
    let mut mean: f64 = 0.0;
    let mut m2: f64 = 0.0;
    for v in buffer.to_f64_vec() {
        n += 1.0;
        let delta = v - mean;
        mean += delta / n;
        let delta2 = v - mean;
        m2 += delta * delta2;
    }
    if n < 1.0 {
        return (f64::NAN, f64::NAN);
    }
    let var = if sample && n > 1.0 {
        m2 / (n - 1.0)
    } else {
        m2 / n
    };
    (mean, var)
}

fn bytes_to_i64_vec(bytes: &[u8]) -> Vec<i64> {
    bytes
        .chunks_exact(8)
        .map(|chunk| i64::from_ne_bytes(chunk.try_into().unwrap()))
        .collect()
}

fn ensure_fixed64(matrix: &MatrixBuffer) -> CoreResult<i32> {
    if matrix.dtype() != DType::Fixed64 {
        return Err("expected fixed64 matrix".into());
    }
    matrix
        .fixed_scale()
        .ok_or_else(|| "fixed64 matrix missing scale metadata".into())
}

fn matrix_to_fixed_vec(matrix: &MatrixBuffer) -> CoreResult<Vec<i64>> {
    if matrix.dtype() != DType::Fixed64 {
        return Err("expected fixed64 matrix".into());
    }
    let contiguous = matrix
        .to_contiguous()
        .map_err(|e| format!("fixed64 contiguous: {e}"))?;
    let bytes = contiguous
        .as_byte_slice()
        .ok_or_else(|| "fixed64 contiguous bytes unavailable".to_string())?;
    Ok(bytes_to_i64_vec(bytes))
}

fn concat_fixed64(axis: usize, matrices: &[MatrixBuffer]) -> CoreResult<MatrixBuffer> {
    let first = matrices
        .first()
        .ok_or_else(|| "concat: expected at least one matrix".to_string())?;
    let scale = ensure_fixed64(first)?;
    match axis {
        0 => {
            let cols = first.cols();
            let mut total_rows = 0usize;
            let mut data: Vec<i64> = Vec::new();
            for m in matrices {
                ensure_fixed64(m)?;
                if m.fixed_scale() != Some(scale) {
                    return Err("concat axis 0: fixed64 scale mismatch".into());
                }
                if m.cols() != cols {
                    return Err("concat axis 0: column sizes differ".into());
                }
                let vec = matrix_to_fixed_vec(m)?;
                total_rows += m.rows();
                data.extend_from_slice(&vec);
            }
            MatrixBuffer::from_fixed_i64_vec(data, total_rows, cols, scale)
        }
        1 => {
            let rows = first.rows();
            let mut total_cols = 0usize;
            let mut parts: Vec<(usize, Vec<i64>)> = Vec::with_capacity(matrices.len());
            for m in matrices {
                ensure_fixed64(m)?;
                if m.fixed_scale() != Some(scale) {
                    return Err("concat axis 1: fixed64 scale mismatch".into());
                }
                if m.rows() != rows {
                    return Err("concat axis 1: row sizes differ".into());
                }
                let cols = m.cols();
                total_cols += cols;
                parts.push((cols, matrix_to_fixed_vec(m)?));
            }
            let mut data: Vec<i64> = Vec::with_capacity(rows * total_cols);
            for row in 0..rows {
                for (cols, vec) in parts.iter() {
                    let start = row * cols;
                    let end = start + cols;
                    data.extend_from_slice(&vec[start..end]);
                }
            }
            MatrixBuffer::from_fixed_i64_vec(data, rows, total_cols, scale)
        }
        _ => unreachable!(),
    }
}

fn where_select_multi_fixed64(
    conditions: &[&MatrixBuffer],
    choices: &[&MatrixBuffer],
    default: Option<&MatrixBuffer>,
    rows: usize,
    cols: usize,
) -> CoreResult<MatrixBuffer> {
    if choices.is_empty() {
        return Err("where_select_multi: requires at least one choice".into());
    }
    let scale = ensure_fixed64(choices[0])?;
    let mut result_data: Vec<i64> = if let Some(default_matrix) = default {
        ensure_fixed64(default_matrix)?;
        if default_matrix.fixed_scale() != Some(scale) {
            return Err("where_select_multi: fixed64 scale mismatch".into());
        }
        let broadcast = default_matrix
            .broadcast_to(rows, cols)
            .map_err(|e| format!("where_select_multi: {e}"))?;
        matrix_to_fixed_vec(&broadcast)?
    } else {
        vec![0; rows * cols]
    };

    for (cond, choice) in conditions.iter().zip(choices.iter()) {
        ensure_fixed64(choice)?;
        if choice.fixed_scale() != Some(scale) {
            return Err("where_select_multi: fixed64 scale mismatch".into());
        }
        let mask = cond
            .broadcast_to(rows, cols)
            .map_err(|e| format!("where_select_multi: {e}"))?
            .to_bool_vec();
        let choice_view = choice
            .broadcast_to(rows, cols)
            .map_err(|e| format!("where_select_multi: {e}"))?;
        let values = matrix_to_fixed_vec(&choice_view)?;
        for (idx, flag) in mask.iter().enumerate() {
            if *flag {
                result_data[idx] = values[idx];
            }
        }
    }

    MatrixBuffer::from_fixed_i64_vec(result_data, rows, cols, scale)
}

pub fn add(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    // Draft: integer add for Fixed64 when scales match
    if a.dtype() == DType::Fixed64 && b.dtype() == DType::Fixed64 {
        ensure_same_shape(a, b)?;
        if a.fixed_scale() != b.fixed_scale() {
            return Err("add(Fixed64): scale mismatch".into());
        }
        let scale = a.fixed_scale().unwrap_or(0);
        let vec_a = matrix_to_fixed_vec(a)?;
        let vec_b = matrix_to_fixed_vec(b)?;
        let mut out: Vec<i64> = Vec::with_capacity(vec_a.len());
        for (lhs, rhs) in vec_a.into_iter().zip(vec_b.into_iter()) {
            let (sum, overflow) = lhs.overflowing_add(rhs);
            if overflow {
                return Err("add(Fixed64): overflow".into());
            }
            out.push(sum);
        }
        return MatrixBuffer::from_fixed_i64_vec(out, a.rows(), a.cols(), scale);
    }
    ensure_same_shape(a, b)?;
    let dtype = promote_pair(a.dtype(), b.dtype()).map_err(|err| format!("add: {err}"))?;

    if dtype == DType::Bool {
        if a.dtype() != DType::Bool || b.dtype() != DType::Bool {
            return Err("add(bool, bool): unsupported mixed boolean addition".into());
        }
        let lhs_std = a.to_contiguous()?;
        let rhs_std = b.to_contiguous()?;
        let lhs = lhs_std.try_as_slice::<bool>()?;
        let rhs = rhs_std.try_as_slice::<bool>()?;
        let mut out: Vec<bool> = Vec::with_capacity(lhs.len());
        for (&x, &y) in lhs.iter().zip(rhs.iter()) {
            out.push(x || y);
        }
        return MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into);
    }

    let lhs_cast = a.cast(dtype)?;
    let rhs_cast = b.cast(dtype)?;
    let lhs_std = lhs_cast.to_contiguous()?;
    let rhs_std = rhs_cast.to_contiguous()?;

    match dtype {
        DType::Int8 => add_signed_numeric::<i8>(&lhs_std, &rhs_std),
        DType::Int16 => add_signed_numeric::<i16>(&lhs_std, &rhs_std),
        DType::Int32 => add_signed_numeric::<i32>(&lhs_std, &rhs_std),
        DType::Int64 => add_signed_numeric::<i64>(&lhs_std, &rhs_std),
        DType::UInt8 => add_unsigned_numeric::<u8>(&lhs_std, &rhs_std),
        DType::UInt16 => add_unsigned_numeric::<u16>(&lhs_std, &rhs_std),
        DType::UInt32 => add_unsigned_numeric::<u32>(&lhs_std, &rhs_std),
        DType::UInt64 => add_unsigned_numeric::<u64>(&lhs_std, &rhs_std),
        DType::Float32 => add_float_numeric::<f32>(&lhs_std, &rhs_std),
        DType::Float64 => add_float_numeric::<f64>(&lhs_std, &rhs_std),
        DType::Bool | DType::Fixed64 => unreachable!(),
    }
}

pub fn sub(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    if a.dtype() == DType::Fixed64 && b.dtype() == DType::Fixed64 {
        ensure_same_shape(a, b)?;
        return sub_fixed64(a, b);
    }
    ensure_same_shape(a, b)?;
    let dtype = promote_pair(a.dtype(), b.dtype()).map_err(|err| format!("sub: {err}"))?;

    if dtype == DType::Bool {
        if a.dtype() != DType::Bool || b.dtype() != DType::Bool {
            return Err("sub(bool, bool): unsupported mixed boolean subtraction".into());
        }
        let lhs_std = a.to_contiguous()?;
        let rhs_std = b.to_contiguous()?;
        let lhs = lhs_std.try_as_slice::<bool>()?;
        let rhs = rhs_std.try_as_slice::<bool>()?;
        let mut out: Vec<bool> = Vec::with_capacity(lhs.len());
        for (&x, &y) in lhs.iter().zip(rhs.iter()) {
            out.push(x & !y);
        }
        return MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into);
    }

    let lhs_cast = a.cast(dtype)?;
    let rhs_cast = b.cast(dtype)?;
    let lhs_std = lhs_cast.to_contiguous()?;
    let rhs_std = rhs_cast.to_contiguous()?;

    match dtype {
        DType::Int8 => sub_signed_numeric::<i8>(&lhs_std, &rhs_std),
        DType::Int16 => sub_signed_numeric::<i16>(&lhs_std, &rhs_std),
        DType::Int32 => sub_signed_numeric::<i32>(&lhs_std, &rhs_std),
        DType::Int64 => sub_signed_numeric::<i64>(&lhs_std, &rhs_std),
        DType::UInt8 => sub_unsigned_numeric::<u8>(&lhs_std, &rhs_std),
        DType::UInt16 => sub_unsigned_numeric::<u16>(&lhs_std, &rhs_std),
        DType::UInt32 => sub_unsigned_numeric::<u32>(&lhs_std, &rhs_std),
        DType::UInt64 => sub_unsigned_numeric::<u64>(&lhs_std, &rhs_std),
        DType::Float32 => sub_float_numeric::<f32>(&lhs_std, &rhs_std),
        DType::Float64 => sub_float_numeric::<f64>(&lhs_std, &rhs_std),
        DType::Bool | DType::Fixed64 => unreachable!(),
    }
}

pub fn mul(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    if a.dtype() == DType::Fixed64 || b.dtype() == DType::Fixed64 {
        return Err("mul(Fixed64): convert operands to float64 before multiplying".into());
    }
    ensure_same_shape(a, b)?;
    let dtype = promote_pair(a.dtype(), b.dtype()).map_err(|err| format!("mul: {err}"))?;

    if dtype == DType::Bool {
        if a.dtype() != DType::Bool || b.dtype() != DType::Bool {
            return Err("mul(bool, bool): unsupported mixed boolean multiplication".into());
        }
        let lhs_std = a.to_contiguous()?;
        let rhs_std = b.to_contiguous()?;
        let lhs = lhs_std.try_as_slice::<bool>()?;
        let rhs = rhs_std.try_as_slice::<bool>()?;
        let mut out: Vec<bool> = Vec::with_capacity(lhs.len());
        for (&x, &y) in lhs.iter().zip(rhs.iter()) {
            out.push(x && y);
        }
        return MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into);
    }

    let lhs_cast = a.cast(dtype)?;
    let rhs_cast = b.cast(dtype)?;
    let lhs_std = lhs_cast.to_contiguous()?;
    let rhs_std = rhs_cast.to_contiguous()?;

    match dtype {
        DType::Int8 => mul_signed_numeric::<i8>(&lhs_std, &rhs_std),
        DType::Int16 => mul_signed_numeric::<i16>(&lhs_std, &rhs_std),
        DType::Int32 => mul_signed_numeric::<i32>(&lhs_std, &rhs_std),
        DType::Int64 => mul_signed_numeric::<i64>(&lhs_std, &rhs_std),
        DType::UInt8 => mul_unsigned_numeric::<u8>(&lhs_std, &rhs_std),
        DType::UInt16 => mul_unsigned_numeric::<u16>(&lhs_std, &rhs_std),
        DType::UInt32 => mul_unsigned_numeric::<u32>(&lhs_std, &rhs_std),
        DType::UInt64 => mul_unsigned_numeric::<u64>(&lhs_std, &rhs_std),
        DType::Float32 => mul_float_numeric::<f32>(&lhs_std, &rhs_std),
        DType::Float64 => mul_float_numeric::<f64>(&lhs_std, &rhs_std),
        DType::Bool | DType::Fixed64 => unreachable!(),
    }
}

pub fn div(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    if a.dtype() == DType::Fixed64 || b.dtype() == DType::Fixed64 {
        return Err("div(Fixed64): convert operands to float64 before dividing".into());
    }
    ensure_same_shape(a, b)?;
    let dtype = promote_pair(a.dtype(), b.dtype()).map_err(|err| format!("div: {err}"))?;

    if dtype == DType::Bool {
        if a.dtype() != DType::Bool || b.dtype() != DType::Bool {
            return Err("div(bool, bool): unsupported mixed boolean division".into());
        }
        let lhs_std = a.to_contiguous()?;
        let rhs_std = b.to_contiguous()?;
        let lhs = lhs_std.try_as_slice::<bool>()?;
        let rhs = rhs_std.try_as_slice::<bool>()?;
        let mut out: Vec<bool> = Vec::with_capacity(lhs.len());
        for (&x, &y) in lhs.iter().zip(rhs.iter()) {
            if !y {
                return Err("div(bool, bool): division by false".into());
            }
            out.push(x);
        }
        return MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into);
    }

    let lhs_cast = a.cast(dtype)?;
    let rhs_cast = b.cast(dtype)?;
    let lhs_std = lhs_cast.to_contiguous()?;
    let rhs_std = rhs_cast.to_contiguous()?;

    match dtype {
        DType::Int8 => div_signed_numeric::<i8>(&lhs_std, &rhs_std),
        DType::Int16 => div_signed_numeric::<i16>(&lhs_std, &rhs_std),
        DType::Int32 => div_signed_numeric::<i32>(&lhs_std, &rhs_std),
        DType::Int64 => div_signed_numeric::<i64>(&lhs_std, &rhs_std),
        DType::UInt8 => div_unsigned_numeric::<u8>(&lhs_std, &rhs_std),
        DType::UInt16 => div_unsigned_numeric::<u16>(&lhs_std, &rhs_std),
        DType::UInt32 => div_unsigned_numeric::<u32>(&lhs_std, &rhs_std),
        DType::UInt64 => div_unsigned_numeric::<u64>(&lhs_std, &rhs_std),
        DType::Float32 => div_float_numeric::<f32>(&lhs_std, &rhs_std),
        DType::Float64 => div_float_numeric::<f64>(&lhs_std, &rhs_std),
        DType::Bool | DType::Fixed64 => unreachable!(),
    }
}

pub fn neg(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    match matrix.dtype() {
        DType::Fixed64 => neg_fixed64(matrix),
        DType::Bool => {
            let std = matrix.to_contiguous()?;
            let src = std.try_as_slice::<bool>()?;
            let mut out: Vec<bool> = Vec::with_capacity(src.len());
            for &value in src {
                out.push(!value);
            }
            MatrixBuffer::from_vec(out, matrix.rows(), matrix.cols()).map_err(Into::into)
        }
        DType::Int8 => {
            let std = matrix.to_contiguous()?;
            neg_signed_numeric::<i8>(&std)
        }
        DType::Int16 => {
            let std = matrix.to_contiguous()?;
            neg_signed_numeric::<i16>(&std)
        }
        DType::Int32 => {
            let std = matrix.to_contiguous()?;
            neg_signed_numeric::<i32>(&std)
        }
        DType::Int64 => {
            let std = matrix.to_contiguous()?;
            neg_signed_numeric::<i64>(&std)
        }
        DType::UInt8 | DType::UInt16 | DType::UInt32 | DType::UInt64 => {
            Err("neg: unsigned dtypes are not supported; cast to a signed dtype first".into())
        }
        DType::Float32 => {
            let std = matrix.to_contiguous()?;
            neg_float_numeric::<f32>(&std)
        }
        DType::Float64 => {
            let std = matrix.to_contiguous()?;
            neg_float_numeric::<f64>(&std)
        }
    }
}

fn add_signed_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let min = T::min_value()
        .to_i128()
        .ok_or_else(|| "failed to convert minimum to i128".to_string())?;
    let max = T::max_value()
        .to_i128()
        .ok_or_else(|| "failed to convert maximum to i128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let sum = x.to_i128().unwrap() + y.to_i128().unwrap();
        let clamped = sum.clamp(min, max);
        let value = T::from_i128(clamped)
            .ok_or_else(|| "failed to cast sum back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn add_unsigned_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Unsigned + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let max = T::max_value()
        .to_u128()
        .ok_or_else(|| "failed to convert maximum to u128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let sum = x.to_u128().unwrap() + y.to_u128().unwrap();
        let clamped = if sum > max { max } else { sum };
        let value = T::from_u128(clamped)
            .ok_or_else(|| "failed to cast sum back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn add_float_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        out.push(x + y);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn sub_signed_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let min = T::min_value()
        .to_i128()
        .ok_or_else(|| "failed to convert minimum to i128".to_string())?;
    let max = T::max_value()
        .to_i128()
        .ok_or_else(|| "failed to convert maximum to i128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let diff = x.to_i128().unwrap() - y.to_i128().unwrap();
        let clamped = diff.clamp(min, max);
        let value = T::from_i128(clamped)
            .ok_or_else(|| "failed to cast difference back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn sub_unsigned_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Unsigned + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let left = x.to_u128().unwrap();
        let right = y.to_u128().unwrap();
        let diff = left.saturating_sub(right);
        let value = T::from_u128(diff)
            .ok_or_else(|| "failed to cast difference back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn sub_float_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        out.push(x - y);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn mul_signed_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let min = T::min_value()
        .to_i128()
        .ok_or_else(|| "failed to convert minimum to i128".to_string())?;
    let max = T::max_value()
        .to_i128()
        .ok_or_else(|| "failed to convert maximum to i128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let product = x.to_i128().unwrap() * y.to_i128().unwrap();
        let clamped = product.clamp(min, max);
        let value = T::from_i128(clamped)
            .ok_or_else(|| "failed to cast product back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn mul_unsigned_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Unsigned + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let max = T::max_value()
        .to_u128()
        .ok_or_else(|| "failed to convert maximum to u128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let product = x.to_u128().unwrap() * y.to_u128().unwrap();
        let clamped = if product > max { max } else { product };
        let value = T::from_u128(clamped)
            .ok_or_else(|| "failed to cast product back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn mul_float_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        out.push(x * y);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn div_signed_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let min = T::min_value()
        .to_i128()
        .ok_or_else(|| "failed to convert minimum to i128".to_string())?;
    let max = T::max_value()
        .to_i128()
        .ok_or_else(|| "failed to convert maximum to i128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let divisor = y.to_i128().unwrap();
        if divisor == 0 {
            return Err("div: division by zero".into());
        }
        let dividend = x.to_i128().unwrap();
        let quotient = dividend / divisor;
        let clamped = quotient.clamp(min, max);
        let value = T::from_i128(clamped)
            .ok_or_else(|| "failed to cast quotient back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn div_unsigned_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Unsigned + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        let divisor = y.to_u128().unwrap();
        if divisor == 0 {
            return Err("div: division by zero".into());
        }
        let dividend = x.to_u128().unwrap();
        let quotient = dividend / divisor;
        let value = T::from_u128(quotient)
            .ok_or_else(|| "failed to cast quotient back to target dtype".to_string())?;
        out.push(value);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn div_float_numeric<T>(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let lhs = a.try_as_slice::<T>()?;
    let rhs = b.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(lhs.len());
    for (&x, &y) in lhs.iter().zip(rhs.iter()) {
        out.push(x / y);
    }
    MatrixBuffer::from_vec(out, a.rows(), a.cols()).map_err(Into::into)
}

fn neg_signed_numeric<T>(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: PrimInt + Signed + Bounded + ToPrimitive + FromPrimitive + ElementTrait,
{
    let values = matrix.try_as_slice::<T>()?;
    let min = T::min_value()
        .to_i128()
        .ok_or_else(|| "failed to convert minimum to i128".to_string())?;
    let max = T::max_value()
        .to_i128()
        .ok_or_else(|| "failed to convert maximum to i128".to_string())?;
    let mut out: Vec<T> = Vec::with_capacity(values.len());
    for &value in values.iter() {
        let negated = -value.to_i128().unwrap();
        let clamped = negated.clamp(min, max);
        let casted = T::from_i128(clamped)
            .ok_or_else(|| "failed to cast negated value back to target dtype".to_string())?;
        out.push(casted);
    }
    MatrixBuffer::from_vec(out, matrix.rows(), matrix.cols()).map_err(Into::into)
}

fn neg_float_numeric<T>(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer>
where
    T: Float + ElementTrait,
{
    let values = matrix.try_as_slice::<T>()?;
    let mut out: Vec<T> = Vec::with_capacity(values.len());
    for &value in values.iter() {
        out.push(-value);
    }
    MatrixBuffer::from_vec(out, matrix.rows(), matrix.cols()).map_err(Into::into)
}

fn sub_fixed64(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    if a.fixed_scale() != b.fixed_scale() {
        return Err("sub(Fixed64): scale mismatch".into());
    }
    let scale = ensure_fixed64(a)?;
    let vec_a = matrix_to_fixed_vec(a)?;
    let vec_b = matrix_to_fixed_vec(b)?;
    let mut out: Vec<i64> = Vec::with_capacity(vec_a.len());
    for (lhs, rhs) in vec_a.into_iter().zip(vec_b.into_iter()) {
        let (diff, overflow) = lhs.overflowing_sub(rhs);
        if overflow {
            return Err("sub(Fixed64): overflow".into());
        }
        out.push(diff);
    }
    MatrixBuffer::from_fixed_i64_vec(out, a.rows(), a.cols(), scale)
}

fn neg_fixed64(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    let scale = ensure_fixed64(matrix)?;
    let vec = matrix_to_fixed_vec(matrix)?;
    let mut out: Vec<i64> = Vec::with_capacity(vec.len());
    for value in vec.into_iter() {
        let (negated, overflow) = value.overflowing_neg();
        if overflow {
            return Err("neg(Fixed64): overflow".into());
        }
        out.push(negated);
    }
    MatrixBuffer::from_fixed_i64_vec(out, matrix.rows(), matrix.cols(), scale)
}

pub fn matmul(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    if a.cols() != b.rows() {
        return Err("matmul: inner dimensions do not match".into());
    }
    if a.dtype() == DType::Fixed64 || b.dtype() == DType::Fixed64 {
        return Err("matmul(Fixed64): convert operands to float64 before multiplying".into());
    }
    let dtype = promote_pair(a.dtype(), b.dtype()).map_err(|err| format!("where_select: {err}"))?;

    let a_matrix = Array2::from_shape_vec((a.rows(), a.cols()), a.to_f64_vec())
        .map_err(|_| "failed to reshape left matrix")?;
    let b_matrix = Array2::from_shape_vec((b.rows(), b.cols()), b.to_f64_vec())
        .map_err(|_| "failed to reshape right matrix")?;
    let product = a_matrix.dot(&b_matrix);

    MatrixBuffer::from_f64_vec(
        dtype,
        product.nrows(),
        product.ncols(),
        product.into_raw_vec(),
    )
    .map_err(Into::into)
}

pub fn clip(buffer: &MatrixBuffer, min: f64, max: f64) -> CoreResult<MatrixBuffer> {
    if min > max {
        return Err("clip: min must be <= max".into());
    }
    if buffer.dtype() == DType::Fixed64 {
        return Err("clip(Fixed64): convert to float64 before clipping".into());
    }
    let dtype = buffer.dtype();
    let clipped: Vec<f64> = buffer
        .to_f64_vec()
        .into_iter()
        .map(|v| v.clamp(min, max))
        .collect();

    MatrixBuffer::from_f64_vec(dtype, buffer.rows(), buffer.cols(), clipped).map_err(Into::into)
}

pub fn where_select(
    condition: &MatrixBuffer,
    a: &MatrixBuffer,
    b: &MatrixBuffer,
) -> CoreResult<MatrixBuffer> {
    where_select_multi(&[condition], &[a], Some(b))
}

pub fn where_select_multi(
    conditions: &[&MatrixBuffer],
    choices: &[&MatrixBuffer],
    default: Option<&MatrixBuffer>,
) -> CoreResult<MatrixBuffer> {
    if conditions.len() != choices.len() {
        return Err("where_select_multi: number of conditions must equal number of choices".into());
    }
    let mut target_shape: Option<(usize, usize)> = None;
    for matrix in conditions.iter().chain(choices.iter()).copied() {
        target_shape = Some(match target_shape {
            None => (matrix.rows(), matrix.cols()),
            Some(shape) => broadcast_pair(shape, (matrix.rows(), matrix.cols()))
                .ok_or_else(|| "where_select_multi: cannot broadcast inputs".to_string())?,
        });
    }
    if let Some(default_matrix) = default {
        target_shape = Some(match target_shape {
            None => (default_matrix.rows(), default_matrix.cols()),
            Some(shape) => broadcast_pair(shape, (default_matrix.rows(), default_matrix.cols()))
                .ok_or_else(|| "where_select_multi: cannot broadcast default".to_string())?,
        });
    }
    let (rows, cols) = target_shape
        .ok_or_else(|| "where_select_multi: requires at least one input".to_string())?;

    let mut dtype_candidates: Vec<DType> = choices.iter().map(|m| m.dtype()).collect();
    if let Some(default_matrix) = default {
        dtype_candidates.push(default_matrix.dtype());
    }
    let dtype = promote_many(&dtype_candidates)
        .map_err(|err| format!("where_select_multi: {err}"))?
        .ok_or("where_select_multi: unable to determine dtype")?;

    if dtype == DType::Fixed64 {
        return where_select_multi_fixed64(conditions, choices, default, rows, cols);
    }

    let mut result = if let Some(default_matrix) = default {
        default_matrix
            .broadcast_to(rows, cols)
            .and_then(|view| view.cast(dtype))
            .and_then(|view| view.to_contiguous())
            .map_err(|err| format!("where_select_multi: {err}"))?
    } else {
        let zeros = vec![0.0; rows * cols];
        MatrixBuffer::from_f64_vec(dtype, rows, cols, zeros)
            .map_err(|err| format!("where_select_multi: {err}"))?
    };

    match dtype {
        DType::Bool => assign_where::<bool>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Int8 => assign_where::<i8>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Int16 => assign_where::<i16>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Int32 => assign_where::<i32>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Int64 => assign_where::<i64>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::UInt8 => assign_where::<u8>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::UInt16 => assign_where::<u16>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::UInt32 => assign_where::<u32>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::UInt64 => assign_where::<u64>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Float32 => assign_where::<f32>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Float64 => assign_where::<f64>(&mut result, dtype, conditions, choices, rows, cols)?,
        DType::Fixed64 => unreachable!("fixed64 handled earlier"),
    }

    Ok(result)
}

pub fn concat(axis: usize, matrices: &[MatrixBuffer]) -> CoreResult<MatrixBuffer> {
    if matrices.is_empty() {
        return Err("concat: expected at least one matrix".into());
    }
    if axis > 1 {
        return Err("concat: axis out of range".into());
    }

    let dtype = promote_many(&matrices.iter().map(|m| m.dtype()).collect::<Vec<_>>())
        .map_err(|err| format!("concat: {err}"))?
        .ok_or("concat: unable to determine dtype")?;
    let casted: Vec<MatrixBuffer> = matrices
        .iter()
        .map(|m| m.cast(dtype))
        .collect::<Result<_, _>>()?;

    if dtype == DType::Fixed64 {
        return concat_fixed64(axis, &casted);
    }

    let rows = casted[0].rows();
    let cols = casted[0].cols();

    match axis {
        0 => {
            let mut total_rows = 0;
            for m in &casted {
                if m.cols() != cols {
                    return Err("concat axis 0: column sizes differ".into());
                }
                total_rows += m.rows();
            }
            let mut data = Vec::with_capacity(total_rows * cols * dtype.size_of());
            for m in &casted {
                if let Some(bytes) = m.as_byte_slice() {
                    data.extend_from_slice(bytes);
                } else {
                    let bytes = m.to_contiguous_bytes_vec();
                    data.extend_from_slice(&bytes);
                }
            }
            MatrixBuffer::from_bytes(dtype, total_rows, cols, data).map_err(Into::into)
        }
        1 => {
            let mut total_cols = 0;
            for m in &casted {
                if m.rows() != rows {
                    return Err("concat axis 1: row sizes differ".into());
                }
                total_cols += m.cols();
            }
            let mut data = Vec::with_capacity(rows * total_cols * dtype.size_of());
            for row in 0..rows {
                for m in &casted {
                    let row_width = m.cols() * dtype.size_of();
                    if let Some(bytes) = m.as_byte_slice() {
                        let start = row * row_width;
                        let end = start + row_width;
                        data.extend_from_slice(&bytes[start..end]);
                    } else {
                        let mut temp = vec![0u8; row_width];
                        m.copy_row_into(row, &mut temp);
                        data.extend_from_slice(&temp);
                    }
                }
            }
            MatrixBuffer::from_bytes(dtype, rows, total_cols, data).map_err(Into::into)
        }
        _ => unreachable!(),
    }
}

pub fn stack(axis: usize, matrices: &[MatrixBuffer]) -> CoreResult<MatrixBuffer> {
    concat(axis, matrices)
}

pub fn transpose(matrix: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    matrix
        .transpose()
        .map_err(|err| format!("transpose: {err}"))
}

pub fn broadcast_to(matrix: &MatrixBuffer, rows: usize, cols: usize) -> CoreResult<MatrixBuffer> {
    matrix
        .broadcast_to(rows, cols)
        .map_err(|err| format!("broadcast_to: {err}"))
}

pub fn take(matrix: &MatrixBuffer, axis: usize, indices: &[isize]) -> CoreResult<MatrixBuffer> {
    matrix
        .take(axis, indices)
        .map_err(|err| format!("take: {err}"))
}

pub fn put(
    matrix: &MatrixBuffer,
    axis: usize,
    indices: &[isize],
    values: &MatrixBuffer,
) -> CoreResult<MatrixBuffer> {
    match axis {
        0 => {
            if values.cols() != matrix.cols() || values.rows() != indices.len() {
                return Err("put axis 0: values shape must match indices x cols".into());
            }
            let col_indices: Vec<isize> = (0..matrix.cols()).map(|c| c as isize).collect();
            matrix
                .scatter(indices, &col_indices, values, false)
                .map_err(|err| format!("put axis 0: {err}"))
        }
        1 => {
            if values.rows() != matrix.rows() || values.cols() != indices.len() {
                return Err("put axis 1: values shape must match rows x indices".into());
            }
            let row_indices: Vec<isize> = (0..matrix.rows()).map(|r| r as isize).collect();
            matrix
                .scatter(&row_indices, indices, values, false)
                .map_err(|err| format!("put axis 1: {err}"))
        }
        _ => Err("put: axis must be 0 or 1".into()),
    }
}

pub fn gather(
    matrix: &MatrixBuffer,
    row_indices: &[isize],
    col_indices: &[isize],
) -> CoreResult<MatrixBuffer> {
    matrix
        .gather(row_indices, col_indices, false)
        .map_err(|err| format!("gather: {err}"))
}

pub fn gather_pairs(
    matrix: &MatrixBuffer,
    row_indices: &[isize],
    col_indices: &[isize],
) -> CoreResult<MatrixBuffer> {
    matrix
        .gather(row_indices, col_indices, true)
        .map_err(|err| format!("gather_pairs: {err}"))
}

pub fn scatter(
    matrix: &MatrixBuffer,
    row_indices: &[isize],
    col_indices: &[isize],
    values: &MatrixBuffer,
) -> CoreResult<MatrixBuffer> {
    matrix
        .scatter(row_indices, col_indices, values, false)
        .map_err(|err| format!("scatter: {err}"))
}

pub fn scatter_pairs(
    matrix: &MatrixBuffer,
    row_indices: &[isize],
    col_indices: &[isize],
    values: &MatrixBuffer,
) -> CoreResult<MatrixBuffer> {
    matrix
        .scatter(row_indices, col_indices, values, true)
        .map_err(|err| format!("scatter_pairs: {err}"))
}

#[cfg(feature = "linalg")]
pub fn svd(buffer: &MatrixBuffer) -> CoreResult<(MatrixBuffer, MatrixBuffer, MatrixBuffer)> {
    let matrix = DMatrix::from_row_slice(buffer.rows(), buffer.cols(), &buffer.to_f64_vec());
    let svd = matrix.svd(true, true);
    let u = svd
        .u
        .ok_or_else(|| "SVD did not return U matrix".to_string())?;
    let vt = svd
        .v_t
        .ok_or_else(|| "SVD did not return V^T matrix".to_string())?;
    let sigma = MatrixBuffer::from_f64_vec(
        DType::Float64,
        1,
        svd.singular_values.len(),
        svd.singular_values.iter().copied().collect(),
    )?;
    let u_buf =
        MatrixBuffer::from_f64_vec(DType::Float64, u.nrows(), u.ncols(), u.as_slice().to_vec())?;
    let vt_buf = MatrixBuffer::from_f64_vec(
        DType::Float64,
        vt.nrows(),
        vt.ncols(),
        vt.as_slice().to_vec(),
    )?;
    Ok((u_buf, sigma, vt_buf))
}

#[cfg(feature = "linalg")]
pub fn qr(buffer: &MatrixBuffer) -> CoreResult<(MatrixBuffer, MatrixBuffer)> {
    let matrix = DMatrix::from_row_slice(buffer.rows(), buffer.cols(), &buffer.to_f64_vec());
    let qr = matrix.qr();
    let q_buf = MatrixBuffer::from_f64_vec(
        DType::Float64,
        qr.q().nrows(),
        qr.q().ncols(),
        qr.q().as_slice().to_vec(),
    )?;
    let r_buf = MatrixBuffer::from_f64_vec(
        DType::Float64,
        qr.r().nrows(),
        qr.r().ncols(),
        qr.r().as_slice().to_vec(),
    )?;
    Ok((q_buf, r_buf))
}

#[cfg(feature = "linalg")]
pub fn solve(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<MatrixBuffer> {
    if a.rows() != a.cols() {
        return Err("solve: matrix A must be square".into());
    }
    if a.rows() != b.rows() {
        return Err("solve: RHS has incompatible shape".into());
    }
    let a_mat = DMatrix::from_row_slice(a.rows(), a.cols(), &a.to_f64_vec());
    let b_mat = DMatrix::from_row_slice(b.rows(), b.cols(), &b.to_f64_vec());
    let solution = a_mat
        .lu()
        .solve(&b_mat)
        .ok_or_else(|| "solve failed: singular matrix".to_string())?;
    MatrixBuffer::from_f64_vec(
        DType::Float64,
        solution.nrows(),
        solution.ncols(),
        solution.as_slice().to_vec(),
    )
    .map_err(Into::into)
}

#[cfg(feature = "linalg")]
pub fn eigen(buffer: &MatrixBuffer) -> CoreResult<(MatrixBuffer, MatrixBuffer)> {
    if buffer.rows() != buffer.cols() {
        return Err("eigen: matrix must be square".into());
    }
    let mat = DMatrix::from_row_slice(buffer.rows(), buffer.cols(), &buffer.to_f64_vec());
    let eigen = SymmetricEigen::new(mat);
    let values = MatrixBuffer::from_f64_vec(
        DType::Float64,
        eigen.eigenvalues.len(),
        1,
        eigen.eigenvalues.as_slice().to_vec(),
    )?;
    let vectors = MatrixBuffer::from_f64_vec(
        DType::Float64,
        eigen.eigenvectors.nrows(),
        eigen.eigenvectors.ncols(),
        eigen.eigenvectors.as_slice().to_vec(),
    )?;
    Ok((values, vectors))
}

#[cfg(feature = "npy")]
const NPY_MAGIC: &[u8] = b"\x93NUMPY";
#[cfg(feature = "npy")]
const NPY_HEADER_ALIGNMENT: usize = 64;

#[cfg(feature = "npy")]
fn dtype_to_numpy_descr(dtype: DType) -> &'static str {
    match dtype {
        DType::Bool => "|b1",
        DType::Int8 => "|i1",
        DType::UInt8 => "|u1",
        DType::Int16 => "<i2",
        DType::UInt16 => "<u2",
        DType::Int32 => "<i4",
        DType::UInt32 => "<u4",
        DType::Int64 | DType::Fixed64 => "<i8",
        DType::UInt64 => "<u8",
        DType::Float32 => "<f4",
        DType::Float64 => "<f8",
    }
}

#[cfg(feature = "npy")]
fn numpy_descr_to_dtype(descr: &str, override_dtype: Option<&str>) -> CoreResult<DType> {
    if let Some(explicit) = override_dtype {
        return match explicit {
            "bool" => Ok(DType::Bool),
            "int8" => Ok(DType::Int8),
            "uint8" => Ok(DType::UInt8),
            "int16" => Ok(DType::Int16),
            "uint16" => Ok(DType::UInt16),
            "int32" => Ok(DType::Int32),
            "uint32" => Ok(DType::UInt32),
            "int64" => Ok(DType::Int64),
            "uint64" => Ok(DType::UInt64),
            "float32" => Ok(DType::Float32),
            "float64" => Ok(DType::Float64),
            "fixed64" => Ok(DType::Fixed64),
            other => Err(format!("read_npy: unrecognised dtype override '{other}'")),
        };
    }
    match descr {
        "|b1" => Ok(DType::Bool),
        "|i1" | "i1" | "b" => Ok(DType::Int8),
        "|u1" | "u1" | "B" => Ok(DType::UInt8),
        "<i2" => Ok(DType::Int16),
        "<u2" => Ok(DType::UInt16),
        "<i4" => Ok(DType::Int32),
        "<u4" => Ok(DType::UInt32),
        "<i8" => Ok(DType::Int64),
        "<u8" => Ok(DType::UInt64),
        "<f4" => Ok(DType::Float32),
        "<f8" => Ok(DType::Float64),
        other => Err(format!(
            "read_npy: unsupported descriptor '{other}'; ensure data is little-endian"
        )),
    }
}

#[cfg(feature = "npy")]
fn assemble_npy_header(dict_repr: &str) -> CoreResult<Vec<u8>> {
    for &(major, minor, len_bytes) in &[(1u8, 0u8, 2usize), (2u8, 0u8, 4usize)] {
        let base = NPY_MAGIC.len() + 2 + len_bytes;
        let mut body = dict_repr.as_bytes().to_vec();
        let padding_target = base + body.len() + 1;
        let padding =
            (NPY_HEADER_ALIGNMENT - (padding_target % NPY_HEADER_ALIGNMENT)) % NPY_HEADER_ALIGNMENT;
        body.extend(std::iter::repeat(b' ').take(padding));
        body.push(b'\n');
        let header_len = body.len();
        if len_bytes == 2 && header_len > u16::MAX as usize {
            continue;
        }

        let mut header = Vec::with_capacity(base + header_len);
        header.extend_from_slice(NPY_MAGIC);
        header.push(major);
        header.push(minor);
        if len_bytes == 2 {
            header.extend_from_slice(&(header_len as u16).to_le_bytes());
        } else {
            header.extend_from_slice(&(header_len as u32).to_le_bytes());
        }
        header.extend_from_slice(&body);
        return Ok(header);
    }
    Err("write_npy: header too long to encode".into())
}

#[cfg(feature = "npy")]
fn make_npy_header(dtype: DType, rows: usize, cols: usize, fixed_scale: Option<i32>) -> CoreResult<Vec<u8>> {
    let descr = dtype_to_numpy_descr(dtype);
    let mut dict = format!(
        "{{'descr': '{}', 'fortran_order': False, 'shape': ({}, {})",
        descr, rows, cols
    );
    dict.push_str(&format!(", 'numjs_dtype': '{}'", dtype.as_str()));
    if let Some(scale) = fixed_scale {
        dict.push_str(&format!(", 'numjs_fixed_scale': {}", scale));
    }
    dict.push('}');
    assemble_npy_header(&dict)
}

#[cfg(feature = "npy")]
fn encode_npy_data(buffer: &MatrixBuffer) -> CoreResult<Vec<u8>> {
    let len = buffer.len();
    match buffer.dtype() {
        DType::Bool => {
            let slice = buffer.try_as_slice::<bool>()?;
            let mut bytes = Vec::with_capacity(len);
            for &value in slice {
                bytes.push(if value { 1u8 } else { 0u8 });
            }
            Ok(bytes)
        }
        DType::Int8 => {
            let slice = buffer.try_as_slice::<i8>()?;
            Ok(slice.iter().map(|&value| value.to_le_bytes()[0]).collect())
        }
        DType::UInt8 => {
            let slice = buffer.try_as_slice::<u8>()?;
            Ok(slice.to_vec())
        }
        DType::Int16 => {
            let slice = buffer.try_as_slice::<i16>()?;
            let mut bytes = Vec::with_capacity(len * 2);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::UInt16 => {
            let slice = buffer.try_as_slice::<u16>()?;
            let mut bytes = Vec::with_capacity(len * 2);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::Int32 => {
            let slice = buffer.try_as_slice::<i32>()?;
            let mut bytes = Vec::with_capacity(len * 4);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::UInt32 => {
            let slice = buffer.try_as_slice::<u32>()?;
            let mut bytes = Vec::with_capacity(len * 4);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::Int64 => {
            let slice = buffer.try_as_slice::<i64>()?;
            let mut bytes = Vec::with_capacity(len * 8);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::UInt64 => {
            let slice = buffer.try_as_slice::<u64>()?;
            let mut bytes = Vec::with_capacity(len * 8);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::Float32 => {
            let slice = buffer.try_as_slice::<f32>()?;
            let mut bytes = Vec::with_capacity(len * 4);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::Float64 => {
            let slice = buffer.try_as_slice::<f64>()?;
            let mut bytes = Vec::with_capacity(len * 8);
            for &value in slice {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
        DType::Fixed64 => {
            let values = matrix_to_fixed_vec(buffer)?;
            let mut bytes = Vec::with_capacity(values.len() * 8);
            for value in values {
                bytes.extend_from_slice(&value.to_le_bytes());
            }
            Ok(bytes)
        }
    }
}

#[cfg(feature = "npy")]
fn encode_matrix_to_npy_bytes(buffer: &MatrixBuffer) -> CoreResult<Vec<u8>> {
    let contiguous = buffer.to_contiguous()?;
    let dtype = contiguous.dtype();
    let fixed_scale = if dtype == DType::Fixed64 {
        Some(ensure_fixed64(&contiguous)?)
    } else {
        None
    };
    let mut header = make_npy_header(dtype, contiguous.rows(), contiguous.cols(), fixed_scale)?;
    let mut data = encode_npy_data(&contiguous)?;
    header.append(&mut data);
    Ok(header)
}

#[cfg(feature = "npy")]
fn reorder_from_fortran<T: Copy>(values: &[T], rows: usize, cols: usize) -> Vec<T> {
    let mut out = Vec::with_capacity(rows * cols);
    for r in 0..rows {
        for c in 0..cols {
            out.push(values[c * rows + r]);
        }
    }
    out
}

#[cfg(feature = "npy")]
fn parse_npy_header(bytes: &[u8]) -> CoreResult<(usize, DType, usize, usize, bool, Option<i32>)> {
    if bytes.len() < NPY_MAGIC.len() + 4 {
        return Err("read_npy: payload is too short".into());
    }
    if &bytes[..NPY_MAGIC.len()] != NPY_MAGIC {
        return Err("read_npy: invalid magic string".into());
    }
    let major = bytes[NPY_MAGIC.len()];
    let minor = bytes[NPY_MAGIC.len() + 1];
    let mut offset = NPY_MAGIC.len() + 2;
    let header_len = match (major, minor) {
        (1, 0) => {
            let raw = bytes
                .get(offset..offset + 2)
                .ok_or_else(|| "read_npy: missing header length".to_string())?;
            offset += 2;
            u16::from_le_bytes([raw[0], raw[1]]) as usize
        }
        (2, 0) | (3, 0) => {
            let raw = bytes
                .get(offset..offset + 4)
                .ok_or_else(|| "read_npy: missing header length".to_string())?;
            offset += 4;
            u32::from_le_bytes([raw[0], raw[1], raw[2], raw[3]]) as usize
        }
        _ => {
            return Err(format!(
                "read_npy: unsupported format version {major}.{minor}"
            ))
        }
    };
    let header_end = offset + header_len;
    let header_bytes = bytes
        .get(offset..header_end)
        .ok_or_else(|| "read_npy: incomplete header".to_string())?;
    if header_len == 0 || header_bytes.last() != Some(&b'\n') {
        return Err("read_npy: malformed header".into());
    }
    let header_str = std::str::from_utf8(&header_bytes[..header_len - 1])
        .map_err(|e| format!("read_npy: header is not valid UTF-8: {e}"))?;
    let meta: PyValue = header_str
        .parse()
        .map_err(|e| format!("read_npy: failed to parse header dict: {e}"))?;
    let dict = meta
        .as_dict()
        .ok_or_else(|| "read_npy: header metadata is not a dict".to_string())?;

    let mut descr: Option<String> = None;
    let mut fortran_order: Option<bool> = None;
    let mut shape: Option<Vec<usize>> = None;
    let mut dtype_override: Option<String> = None;
    let mut fixed_scale: Option<i32> = None;

    for (key, value) in dict {
        let key_str = match key {
            PyValue::String(s) => s.as_str(),
            _ => continue,
        };
        match key_str {
            "descr" => {
                if let PyValue::String(s) = value {
                    descr = Some(s.clone());
                }
            }
            "fortran_order" => {
                if let PyValue::Boolean(flag) = value {
                    fortran_order = Some(*flag);
                }
            }
            "shape" => {
                if let Some(tuple) = value.as_tuple() {
                    let mut dims = Vec::with_capacity(tuple.len());
                    for elem in tuple {
                        let int = elem
                            .as_integer()
                            .ok_or_else(|| "read_npy: shape contains non-integer entries".to_string())?;
                        let dim = int
                            .to_usize()
                            .ok_or_else(|| "read_npy: shape dimension does not fit usize".to_string())?;
                        dims.push(dim);
                    }
                    shape = Some(dims);
                }
            }
            "numjs_dtype" => {
                if let PyValue::String(s) = value {
                    dtype_override = Some(s.clone());
                }
            }
            "numjs_fixed_scale" => {
                if let Some(int) = value.as_integer() {
                    let scale = int
                        .to_i32()
                        .ok_or_else(|| "read_npy: fixed64 scale does not fit i32".to_string())?;
                    fixed_scale = Some(scale);
                }
            }
            _ => {}
        }
    }

    let descr = descr.ok_or_else(|| "read_npy: header missing 'descr' key".to_string())?;
    let fortran_order =
        fortran_order.ok_or_else(|| "read_npy: header missing 'fortran_order' key".to_string())?;
    let shape = shape.ok_or_else(|| "read_npy: header missing 'shape' key".to_string())?;
    if shape.len() != 2 {
        return Err(format!(
            "read_npy: expected 2D array, but header shape is {:?}",
            shape
        ));
    }
    let rows = shape[0];
    let cols = shape[1];
    let dtype = numpy_descr_to_dtype(&descr, dtype_override.as_deref())?;
    if dtype == DType::Fixed64 && fixed_scale.is_none() {
        return Err("read_npy(fixed64): missing 'numjs_fixed_scale' metadata".into());
    }
    Ok((header_end, dtype, rows, cols, fortran_order, fixed_scale))
}

#[cfg(feature = "npy")]
fn decode_matrix_from_bytes(
    bytes: &[u8],
    dtype: DType,
    rows: usize,
    cols: usize,
    fortran: bool,
    fixed_scale: Option<i32>,
) -> CoreResult<MatrixBuffer> {
    let len = rows
        .checked_mul(cols)
        .ok_or_else(|| "read_npy: shape would overflow".to_string())?;
    let expected_bytes = len
        .checked_mul(dtype.size_of())
        .ok_or_else(|| "read_npy: expected byte count overflowed".to_string())?;
    if bytes.len() != expected_bytes {
        return Err(format!(
            "read_npy: expected {expected_bytes} data bytes, found {}",
            bytes.len()
        ));
    }
    match dtype {
        DType::Bool => {
            let mut raw = bytes.to_vec();
            if fortran {
                raw = reorder_from_fortran(&raw, rows, cols);
            }
            let mut values = Vec::with_capacity(len);
            for (index, byte) in raw.into_iter().enumerate() {
                match byte {
                    0 => values.push(false),
                    1 => values.push(true),
                    other => {
                        return Err(format!(
                            "read_npy(bool): invalid byte value {other} at index {index}"
                        ))
                    }
                }
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Int8 => {
            let mut values = bytes.iter().map(|&b| i8::from_le_bytes([b])).collect::<Vec<_>>();
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::UInt8 => {
            let mut values = bytes.to_vec();
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Int16 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(2) {
                values.push(i16::from_le_bytes([chunk[0], chunk[1]]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::UInt16 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(2) {
                values.push(u16::from_le_bytes([chunk[0], chunk[1]]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Int32 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(4) {
                values.push(i32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::UInt32 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(4) {
                values.push(u32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Int64 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(8) {
                values.push(i64::from_le_bytes([
                    chunk[0], chunk[1], chunk[2], chunk[3], chunk[4], chunk[5], chunk[6], chunk[7],
                ]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::UInt64 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(8) {
                values.push(u64::from_le_bytes([
                    chunk[0], chunk[1], chunk[2], chunk[3], chunk[4], chunk[5], chunk[6], chunk[7],
                ]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Float32 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(4) {
                values.push(f32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Float64 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(8) {
                values.push(f64::from_le_bytes([
                    chunk[0], chunk[1], chunk[2], chunk[3], chunk[4], chunk[5], chunk[6], chunk[7],
                ]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_vec(values, rows, cols).map_err(Into::into)
        }
        DType::Fixed64 => {
            let mut values = Vec::with_capacity(len);
            for chunk in bytes.chunks_exact(8) {
                values.push(i64::from_le_bytes([
                    chunk[0], chunk[1], chunk[2], chunk[3], chunk[4], chunk[5], chunk[6], chunk[7],
                ]));
            }
            if fortran {
                values = reorder_from_fortran(&values, rows, cols);
            }
            MatrixBuffer::from_fixed_i64_vec(values, rows, cols, fixed_scale.unwrap())
                .map_err(Into::into)
        }
    }
}

#[cfg(feature = "npy")]
pub fn read_npy_matrix(data: &[u8]) -> CoreResult<MatrixBuffer> {
    let (offset, dtype, rows, cols, fortran, fixed_scale) = parse_npy_header(data)?;
    let payload = data
        .get(offset..)
        .ok_or_else(|| "read_npy: missing array payload".to_string())?;
    decode_matrix_from_bytes(payload, dtype, rows, cols, fortran, fixed_scale)
}

#[cfg(feature = "npy")]
pub fn write_npy_matrix(buffer: &MatrixBuffer) -> CoreResult<Vec<u8>> {
    encode_matrix_to_npy_bytes(buffer)
}

#[cfg(feature = "npy")]
pub fn read_npz_matrices(data: &[u8]) -> CoreResult<Vec<(String, MatrixBuffer)>> {
    let cursor = Cursor::new(data);
    let mut archive = ZipArchive::new(cursor).map_err(|e| format!("failed to read npz: {e}"))?;
    let mut results = Vec::new();
    for index in 0..archive.len() {
        let mut file = archive
            .by_index(index)
            .map_err(|e| format!("npz entry {index} failed: {e}"))?;
        if file.is_dir() {
            continue;
        }
        let name = file.name().to_owned();
        let mut bytes = Vec::new();
        file.read_to_end(&mut bytes)
            .map_err(|e| format!("npz entry {name} read failed: {e}"))?;
        let matrix = read_npy_matrix(&bytes)?;
        results.push((name, matrix));
    }
    Ok(results)
}

#[cfg(feature = "npy")]
pub fn write_npz_matrices(entries: &[(&str, MatrixBuffer)]) -> CoreResult<Vec<u8>> {
    let cursor = Cursor::new(Vec::new());
    let mut writer = ZipWriter::new(cursor);
    let options = FileOptions::default().compression_method(CompressionMethod::Stored);
    for (name, buffer) in entries {
        let bytes = write_npy_matrix(buffer)?;
        writer
            .start_file(*name, options)
            .map_err(|e| format!("write_npz: failed to start entry {name}: {e}"))?;
        writer
            .write_all(&bytes)
            .map_err(|e| format!("write_npz: failed to write entry {name}: {e}"))?;
    }
    let cursor = writer
        .finish()
        .map_err(|e| format!("write_npz: failed to finish archive: {e}"))?;
    Ok(cursor.into_inner())
}

#[cfg(not(feature = "npy"))]
pub fn read_npy_matrix(_data: &[u8]) -> CoreResult<MatrixBuffer> {
    Err("npy support is disabled".into())
}

#[cfg(not(feature = "npy"))]
pub fn write_npy_matrix(_buffer: &MatrixBuffer) -> CoreResult<Vec<u8>> {
    Err("npy support is disabled".into())
}

#[cfg(not(feature = "npy"))]
pub fn read_npz_matrices(_data: &[u8]) -> CoreResult<Vec<(String, MatrixBuffer)>> {
    Err("npz support is disabled".into())
}

#[cfg(not(feature = "npy"))]
pub fn write_npz_matrices(_entries: &[(&str, MatrixBuffer)]) -> CoreResult<Vec<u8>> {
    Err("npz support is disabled".into())
}

fn ensure_same_shape(a: &MatrixBuffer, b: &MatrixBuffer) -> CoreResult<()> {
    if a.rows() != b.rows() || a.cols() != b.cols() {
        return Err("shape mismatch".into());
    }
    Ok(())
}

fn broadcast_pair(a: (usize, usize), b: (usize, usize)) -> Option<(usize, usize)> {
    Some((broadcast_dim(a.0, b.0)?, broadcast_dim(a.1, b.1)?))
}

fn broadcast_dim(a: usize, b: usize) -> Option<usize> {
    if a == b {
        Some(a)
    } else if a == 1 {
        Some(b)
    } else if b == 1 {
        Some(a)
    } else {
        None
    }
}

fn assign_where<T: crate::element::Element + Copy>(
    result: &mut MatrixBuffer,
    dtype: DType,
    conditions: &[&MatrixBuffer],
    choices: &[&MatrixBuffer],
    rows: usize,
    cols: usize,
) -> Result<(), String> {
    let dest = result.as_slice_mut::<T>().ok_or_else(|| {
        format!(
            "where_select_multi: failed to access {} slice",
            dtype.as_str()
        )
    })?;
    for (cond, choice) in conditions.iter().zip(choices.iter()) {
        let mask = cond
            .broadcast_to(rows, cols)
            .map_err(|e| format!("where_select_multi condition broadcast failed: {e}"))?
            .to_bool_vec();
        let cast_choice = choice
            .broadcast_to(rows, cols)
            .map_err(|e| format!("where_select_multi choice broadcast failed: {e}"))?
            .cast(dtype)
            .and_then(|buf| buf.to_contiguous())
            .map_err(|e| format!("where_select_multi choice cast failed: {e}"))?;
        let src = cast_choice
            .as_slice::<T>()
            .ok_or_else(|| "where_select_multi: unable to read casted choice slice".to_string())?;
        apply_mask(dest, src, &mask);
    }
    Ok(())
}

fn apply_mask<T: Copy>(dest: &mut [T], src: &[T], mask: &[bool]) {
    for (index, flag) in mask.iter().enumerate() {
        if *flag {
            dest[index] = src[index];
        }
    }
}

// ---------------------------------------------------------------------
// Tests for stable reductions
// ---------------------------------------------------------------------

#[cfg(test)]
mod tests {
    use super::*;
    use crate::buffer::MatrixBuffer;

    #[test]
    fn test_pairwise_sum_simple() {
        let buf = MatrixBuffer::from_f64_vec(
            crate::dtype::DType::Float64,
            1,
            5,
            vec![1e16, 1.0, 1.0, -1e16, 1.0],
        )
        .unwrap();
        let naive: f64 = buf.to_f64_vec().iter().sum();
        let stable_buf = sum(&buf, None).expect("sum");
        assert_eq!(stable_buf.dtype(), DType::Float64);
        let stable = stable_buf.try_as_slice::<f64>().unwrap()[0];
        // naive may be 1.0 or 0.0 depending on accumulation; stable should be 3.0 or close
        assert!(
            stable > 0.5,
            "stable sum too small: {} (naive={})",
            stable,
            naive
        );
    }

    #[test]
    fn test_welford_mean_var() {
        let data: Vec<f64> = (0..1000).map(|i| (i as f64) / 10.0).collect();
        let buf =
            MatrixBuffer::from_f64_vec(crate::dtype::DType::Float64, 1, data.len(), data).unwrap();
        let (mean, var) = welford_mean_variance(&buf, false);
        assert!((mean - 49.95).abs() < 1e-9);
        assert!(var > 0.0);
    }

    #[test]
    fn test_fixed64_concat_preserves_scale() {
        let a = MatrixBuffer::from_fixed_i64_vec(vec![150, 250], 1, 2, 2).unwrap();
        let b = MatrixBuffer::from_fixed_i64_vec(vec![350, 450], 1, 2, 2).unwrap();
        let stacked = concat(0, &[a.clone(), b.clone()]).expect("concat axis 0");
        assert_eq!(stacked.fixed_scale(), Some(2));
        assert_eq!(stacked.rows(), 2);
        assert_eq!(stacked.cols(), 2);
        assert_eq!(stacked.to_f64_vec(), vec![1.5, 2.5, 3.5, 4.5]);

        let wide = concat(1, &[a.clone(), b.clone()]).expect("concat axis 1");
        assert_eq!(wide.fixed_scale(), Some(2));
        assert_eq!(wide.rows(), 1);
        assert_eq!(wide.cols(), 4);
        assert_eq!(wide.to_f64_vec(), vec![1.5, 2.5, 3.5, 4.5]);
    }

    #[test]
    fn test_fixed64_take_and_gather_preserve_scale() {
        let base = MatrixBuffer::from_fixed_i64_vec(vec![100, 200, 300, 400], 2, 2, 1).unwrap();
        let take_row = take(&base, 0, &[1]).expect("take row");
        assert_eq!(take_row.fixed_scale(), Some(1));
        assert_eq!(take_row.rows(), 1);
        assert_eq!(take_row.to_f64_vec(), vec![30.0, 40.0]);

        let gather_pairs = gather(&base, &[0, 1], &[1]).expect("gather outer");
        assert_eq!(gather_pairs.fixed_scale(), Some(1));
        assert_eq!(gather_pairs.to_f64_vec(), vec![20.0, 40.0]);
    }

    #[test]
    fn test_fixed64_where_select() {
        let condition =
            MatrixBuffer::from_vec(vec![true, false, true, false], 2, 2).expect("condition");
        let a = MatrixBuffer::from_fixed_i64_vec(vec![1234, 2234, 3234, 4234], 2, 2, 2).unwrap();
        let b = MatrixBuffer::from_fixed_i64_vec(vec![1000, 2000, 3000, 4000], 2, 2, 2).unwrap();
        let result = where_select(&condition, &a, &b).expect("where select");
        assert_eq!(result.fixed_scale(), Some(2));
        assert_eq!(result.to_f64_vec(), vec![12.34, 20.00, 32.34, 40.00]);
    }

    #[test]
    fn test_fixed64_transpose_preserves_scale() {
        let base = MatrixBuffer::from_fixed_i64_vec(vec![100, 200, 300, 400], 2, 2, 1).unwrap();
        let transposed = transpose(&base).expect("transpose");
        assert_eq!(transposed.fixed_scale(), Some(1));
        assert_eq!(transposed.rows(), 2);
        assert_eq!(transposed.cols(), 2);
        assert_eq!(transposed.to_f64_vec(), vec![10.0, 30.0, 20.0, 40.0]);
    }

    #[test]
    fn test_fixed64_broadcast_preserves_scale() {
        let base = MatrixBuffer::from_fixed_i64_vec(vec![1050, 2050], 1, 2, 2).unwrap();
        let expanded = broadcast_to(&base, 3, 2).expect("broadcast");
        assert_eq!(expanded.fixed_scale(), Some(2));
        assert_eq!(expanded.rows(), 3);
        assert_eq!(expanded.cols(), 2);
        assert_eq!(
            expanded.to_f64_vec(),
            vec![10.5, 20.5, 10.5, 20.5, 10.5, 20.5]
        );
    }

    #[test]
    fn test_sub_bool_difference() {
        let lhs = MatrixBuffer::from_vec(vec![true, true, false], 1, 3).unwrap();
        let rhs = MatrixBuffer::from_vec(vec![false, true, true], 1, 3).unwrap();
        let diff = sub(&lhs, &rhs).expect("bool subtraction");
        assert_eq!(diff.dtype(), DType::Bool);
        assert_eq!(diff.to_bool_vec(), vec![true, false, false]);
    }

    #[test]
    fn test_mul_uint8_saturates() {
        let lhs = MatrixBuffer::from_vec(vec![200u8, 255u8], 1, 2).unwrap();
        let rhs = MatrixBuffer::from_vec(vec![2u8, 2u8], 1, 2).unwrap();
        let prod = mul(&lhs, &rhs).expect("uint8 multiply");
        assert_eq!(prod.dtype(), DType::UInt8);
        let values = prod.try_as_slice::<u8>().unwrap();
        assert_eq!(values, &[255, 255]);
    }

    #[test]
    fn test_div_detects_zero() {
        let lhs = MatrixBuffer::from_vec(vec![7i32, -9i32], 1, 2).unwrap();
        let zeros = MatrixBuffer::from_vec(vec![0i32, 1i32], 1, 2).unwrap();
        let err = div(&lhs, &zeros).expect_err("division by zero should fail");
        assert!(err.contains("division by zero"));
    }

    #[test]
    fn test_neg_behaviour() {
        let signed = MatrixBuffer::from_vec(vec![1i32, -2i32], 1, 2).unwrap();
        let neg_signed = neg(&signed).expect("neg signed");
        assert_eq!(neg_signed.try_as_slice::<i32>().unwrap(), &[-1, 2]);

        let unsigned = MatrixBuffer::from_vec(vec![1u8, 2u8], 1, 2).unwrap();
        let err = neg(&unsigned).expect_err("neg unsigned should error");
        assert!(err.contains("unsigned dtypes"));

        let fixed = MatrixBuffer::from_fixed_i64_vec(vec![150, -20], 1, 2, 1).unwrap();
        let neg_fixed = neg(&fixed).expect("neg fixed");
        assert_eq!(neg_fixed.fixed_scale(), Some(1));
        assert_eq!(neg_fixed.to_f64_vec(), vec![-15.0, 2.0]);
    }

    #[test]
    fn test_sum_int32_accumulates_to_int64() {
        let buf = MatrixBuffer::from_vec(vec![1i32, 2, 3, 4], 2, 2).unwrap();
        let reduced = sum(&buf, None).expect("sum int32");
        assert_eq!(reduced.dtype(), DType::Int64);
        let values = reduced.try_as_slice::<i64>().unwrap();
        assert_eq!(values, &[10]);
    }

    #[test]
    fn test_sum_with_target_dtype() {
        let buf = MatrixBuffer::from_vec(vec![1u16, 2u16, 3u16], 1, 3).unwrap();
        let reduced = sum(&buf, Some(DType::UInt32)).expect("sum u16 -> u32");
        assert_eq!(reduced.dtype(), DType::UInt32);
        let values = reduced.try_as_slice::<u32>().unwrap();
        assert_eq!(values, &[6]);
    }

    #[test]
    fn test_dot_accumulates_to_int64() {
        let lhs = MatrixBuffer::from_vec(vec![1i16, 2i16, 3i16], 1, 3).unwrap();
        let rhs = MatrixBuffer::from_vec(vec![4i16, 5i16, 6i16], 1, 3).unwrap();
        let reduced = dot(&lhs, &rhs, None).expect("dot i16");
        assert_eq!(reduced.dtype(), DType::Int64);
        let values = reduced.try_as_slice::<i64>().unwrap();
        assert_eq!(values, &[32]);
    }

    #[test]
    fn add_fixed64_float_requires_explicit_cast() {
        let fixed = MatrixBuffer::from_fixed_i64_vec(vec![150], 1, 1, 2).unwrap();
        let float = MatrixBuffer::from_vec(vec![1.5f64], 1, 1).unwrap();
        let err = add(&fixed, &float).expect_err("add should reject fixed64 + float");
        assert!(err.contains("fixed64") && err.contains("astype"));
    }

    #[test]
    fn dot_fixed64_float_errors() {
        let fixed = MatrixBuffer::from_fixed_i64_vec(vec![150, 250], 1, 2, 2).unwrap();
        let float = MatrixBuffer::from_vec(vec![1.0f64, 2.0], 1, 2).unwrap();
        let err = dot(&fixed, &float, None).expect_err("dot should reject fixed64 + float");
        assert!(err.contains("astype") && err.contains("dot"));
    }
}

