import {
  tensor,
  tensorAdd,
  tensorMatmul,
  tensorSum,
  tensorSumAxis,
  Tensor,
} from "@jayce789/numjs";

type Logger = (message: string) => void;

function formatMatrix(matrix: Tensor["value"]): string {
  return JSON.stringify(Array.from(matrix.toArray()));
}

export async function runAutogradDemo(log: Logger) {
  log("ğŸ§  Autograd æ¼”ç¤ºï¼šy = sum((W @ x) + b)");

  const x = tensor(
    new Float64Array([1, 2, 3, 4]),
    2,
    2,
    { requiresGrad: false, name: "x" }
  );
  const w = tensor(
    new Float64Array([0.5, -0.25, 1.0, -0.75]),
    2,
    2,
    { requiresGrad: true, name: "W" }
  );
  const b = tensor([0.1, -0.2], 1, 2, { requiresGrad: true, name: "b" });

  const wx = tensorMatmul(w, x);
  const logits = tensorAdd(wx, tensorSumAxis(b, 0));
  const loss = tensorSum(logits);

  log(`â€¢ loss æ•°å€¼: ${formatMatrix(loss.value)}`);

  loss.backward();

  const weightGrad = w.grad?.toArray() ?? [];
  const biasGrad = b.grad?.toArray() ?? [];
  log(`â€¢ W.grad: ${JSON.stringify(Array.from(weightGrad))}`);
  log(`â€¢ b.grad: ${JSON.stringify(Array.from(biasGrad))}`);
  log("æç¤ºï¼šä¿®æ”¹ W/x/b åˆå§‹å€¼å¯è§‚å¯Ÿæ¢¯åº¦å˜åŒ–ã€‚");
}
